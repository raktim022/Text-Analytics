{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzxvbuSPU4UG",
        "outputId": "2ba7efcd-ed29-4bb5-e24d-1b8529812fb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYldJ2-ofDNw"
      },
      "outputs": [],
      "source": [
        "PATH='/content/drive/My Drive/corpus.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wK8UpUjkfDFh"
      },
      "outputs": [],
      "source": [
        "with open(PATH,'r') as f:\n",
        "  corpus=f.read()\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFUSnuY5fC7h",
        "outputId": "646bb112-bfc7-4b22-e7f2-98582c17a147"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4420131"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import re\n",
        "reviews=re.split(\"\\%\\$\\%|\\.|\\?|\\!\",corpus)\n",
        "reviews=[review for review in reviews if review not in \" \"]\n",
        "len(reviews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQAeeJ8V-HfC",
        "outputId": "8fffc5a0-f0c4-4a18-8765-bc9c88d5894f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import re\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from collections import Counter\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "#fd = open('review.txt','r')\n",
        "#sentences = fd.readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5YYpTMRByrC"
      },
      "outputs": [],
      "source": [
        "lemma=WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2><b>Extracting the top 20 Unigram aspects from 500000 reviews</b></h2>"
      ],
      "metadata": {
        "id": "UoChVPglDUk3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLIq36VzmjTy"
      },
      "outputs": [],
      "source": [
        "i=1\n",
        "aspects=\"\"\"{<JJ><NN.*>+},\n",
        "  {<NN.*>+},\n",
        "  {<VB.*><NN.*>},\n",
        "  {<NN.*><VB.*>},\n",
        "  {<NN><NNS>},\n",
        "  \n",
        "  {<NNS><VB.*>},\n",
        "  {<NN.*><JJ>},\n",
        "  {<NN.*><VBZ>},\n",
        "  {<RB.*><JJ>+},\n",
        "  {<RB><VBG>}\n",
        "\"\"\".split(\",\")\n",
        "num_dicts=len(aspects)\n",
        "aspect_dicts=dict()\n",
        "for j in aspects:\n",
        "  aspect_dicts[j]=Counter()\n",
        "for sentence in reviews[:500000]:\n",
        "  sentence=sentence.lower()\n",
        "  sentence=re.sub(\"[^a-zA-Z]+\",\" \",sentence)\n",
        "  tokens=nltk.word_tokenize(sentence)\n",
        "  \n",
        "  lemmatized_tokens=[lemma.lemmatize(token) for token in tokens if token not in stop_words]\n",
        "  #print(lemmatized_tokens)\n",
        "  tags=nltk.pos_tag(lemmatized_tokens)\n",
        "  #print(tags)\n",
        "  for asp in aspects: \n",
        "\n",
        "    cp=nltk.RegexpParser(f\"ASPECT: {asp}\")\n",
        "  \n",
        "    res=cp.parse(tags)\n",
        "    #print(res)\n",
        "    for x in res:\n",
        "      if type(x)==nltk.tree.Tree and x.label()==\"ASPECT\":\n",
        "        for y in x.leaves():\n",
        "          if \"NN\" in y[1]:\n",
        "            aspect=[y[0]]\n",
        "            aspect_dicts[asp].update(aspect)\n",
        "    print(i,end=' sentences processed \\r')\n",
        "    i+=1    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for j in aspects: \n",
        "  print(\"Rule: \",j,\". Aspect: \",aspect_dicts[j].most_common(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ja4czupML6s-",
        "outputId": "aa6bac74-d27d-49b0-f95d-38e7cdfb59d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rule:  {<JJ><NN.*>+} . Aspect:  [('phone', 28337), ('case', 22813), ('product', 12387), ('time', 10498), ('battery', 9786), ('price', 8219), ('use', 7907), ('work', 7787), ('quality', 7716), ('screen', 6806), ('iphone', 6116), ('protector', 5848), ('charge', 5789), ('device', 5131), ('fit', 4988), ('charger', 4669), ('thing', 4331), ('day', 4074), ('protection', 3652), ('look', 3596)]\n",
            "Rule:  \n",
            "  {<NN.*>+} . Aspect:  [('phone', 90078), ('case', 56593), ('work', 27334), ('product', 22218), ('battery', 22066), ('use', 20205), ('time', 19893), ('iphone', 16146), ('screen', 14425), ('charge', 13460), ('price', 13109), ('quality', 11404), ('device', 10533), ('fit', 10482), ('charger', 9898), ('day', 9877), ('protector', 9700), ('thing', 9583), ('problem', 9454), ('look', 8810)]\n",
            "Rule:  \n",
            "  {<VB.*><NN.*>} . Aspect:  [('phone', 27584), ('case', 8444), ('battery', 4097), ('iphone', 3843), ('product', 3584), ('charge', 2683), ('use', 2243), ('work', 2214), ('time', 2149), ('something', 1958), ('way', 1694), ('screen', 1685), ('device', 1617), ('call', 1563), ('day', 1531), ('cable', 1510), ('review', 1420), ('lot', 1315), ('hour', 1269), ('month', 1267)]\n",
            "Rule:  \n",
            "  {<NN.*><VB.*>} . Aspect:  [('case', 13091), ('phone', 12472), ('time', 4784), ('product', 3316), ('battery', 3238), ('day', 3003), ('people', 2650), ('work', 2188), ('charger', 2049), ('device', 2043), ('thing', 2006), ('protector', 1985), ('screen', 1984), ('iphone', 1823), ('use', 1821), ('problem', 1770), ('item', 1743), ('way', 1668), ('get', 1592), ('review', 1576)]\n",
            "Rule:  \n",
            "  {<NN><NNS>} . Aspect:  [('data', 1393), ('people', 1268), ('others', 851), ('phone', 782), ('plantronics', 466), ('price', 360), ('nbsp', 311), ('iphones', 276), ('thanks', 265), ('electronics', 264), ('case', 231), ('protects', 202), ('cheap', 198), ('thats', 193), ('product', 191), ('lot', 188), ('device', 188), ('use', 182), ('smartphones', 179), ('connects', 169)]\n",
            "Rule:  \n",
            "  \n",
            "  {<NNS><VB.*>} . Aspect:  [('people', 2650), ('others', 1305), ('plantronics', 563), ('thanks', 501), ('data', 265), ('allows', 262), ('yes', 260), ('protects', 257), ('thats', 246), ('know', 208), ('electronics', 194), ('iphones', 164), ('glad', 119), ('anti', 119), ('lens', 119), ('sits', 113), ('got', 111), ('smartphones', 109), ('needle', 107), ('connects', 107)]\n",
            "Rule:  \n",
            "  {<NN.*><JJ>} . Aspect:  [('phone', 9313), ('case', 7844), ('work', 6690), ('look', 3419), ('use', 2741), ('bit', 2554), ('product', 2435), ('time', 2419), ('quality', 2158), ('charge', 1924), ('battery', 1857), ('iphone', 1356), ('price', 1328), ('something', 1313), ('feel', 1288), ('link', 1206), ('way', 1204), ('ie', 1158), ('protector', 1143), ('get', 1138)]\n",
            "Rule:  \n",
            "  {<NN.*><VBZ>} . Aspect:  [('case', 1164), ('phone', 317), ('camera', 262), ('product', 162), ('battery', 143), ('cover', 125), ('button', 118), ('use', 115), ('quality', 98), ('life', 93), ('time', 92), ('part', 91), ('unit', 90), ('charger', 88), ('issue', 87), ('iphone', 81), ('feature', 77), ('screen', 77), ('clip', 77), ('protector', 69)]\n",
            "Rule:  \n",
            "  {<RB.*><JJ>+} . Aspect:  []\n",
            "Rule:  \n",
            "  {<RB><VBG>}\n",
            " . Aspect:  []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3><b>Using Pointwise Mutual Information to find the most probable aspect phrases and classify them into Aspects, Opinions and Intensifiers</b></h3>"
      ],
      "metadata": {
        "id": "cgJ7owhdDACp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d--swaBfoZTu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e7855ff-20b5-483c-ff17-2292f7d92b63"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['blink', 'pattern'] ------------ Aspect\n",
            "['ll', 'identify'] ------------ Aspect\n",
            "['mystified', 'red'] ----------- Opinion\n",
            "['sequentially', 'simultaneously'] ------------ Intensifier\n",
            "['proprietary', 'data'] ----------- Opinion\n",
            "['speaking', 'directly'] ----------- Opinion\n",
            "['game', 'frustration'] ------------ Aspect\n",
            "['without', 'aggravation'] ----------- Opinion\n",
            "['method', 'spell'] ------------ Aspect\n",
            "['gotten', 'attached'] ----------- Opinion\n",
            "['functionality', 'certain'] ------------ Aspect\n",
            "['user', 'profiles'] ------------ Aspect\n",
            "['number', 'blocking'] ------------ Aspect\n",
            "['fact', 'currently'] ------------ Aspect\n",
            "['nits', 'pick'] ----------- Opinion\n",
            "['cause', 'eye'] ------------ Aspect\n",
            "['tends', 'toward'] ----------- Opinion\n",
            "['accurate', 'do'] ------------ Aspect\n",
            "['blacklists', 'enabled'] ----------- Opinion\n",
            "['bloatware', 'galling'] ------------ Aspect\n",
            "['brightens', 'skin'] ----------- Opinion\n",
            "['buffering', 'actually'] ----------- Opinion\n",
            "['called', 'interruptions'] ----------- Opinion\n",
            "['calling', 'pro'] ----------- Opinion\n",
            "['center', 'visit'] ------------ Aspect\n",
            "['check', 'red'] ------------ Aspect\n",
            "['compared', 'digital'] ----------- Opinion\n",
            "['deal', 'grand'] ------------ Aspect\n",
            "['delay', 'options'] ------------ Aspect\n",
            "['despite', 'outliers'] ----------- Opinion\n",
            "['egregious', 'bad'] ----------- Opinion\n",
            "['faces', 'smooths'] ----------- Opinion\n",
            "['feel', 'listed'] ------------ Aspect\n",
            "['friends', 'default'] ----------- Opinion\n",
            "['frustration', 'skip'] ------------ Aspect\n",
            "['futile', 'game'] ----------- Opinion\n",
            "['hot', 'mind'] ----------- Opinion\n",
            "['hovers', 'average'] ----------- Opinion\n",
            "['impractical', 'lends'] ----------- Opinion\n",
            "['intuitive', 'accurate'] ----------- Opinion\n",
            "['learn', 'existing'] ------------ Aspect\n",
            "['links', 'emails'] ----------- Opinion\n",
            "['listed', 'neutral'] ----------- Opinion\n",
            "['lte', 'platform'] ------------ Aspect\n",
            "['mind', 'noticeably'] ------------ Aspect\n",
            "['netflix', 'spent'] ----------- Opinion\n",
            "['noted', 'sporadic'] ----------- Opinion\n",
            "['noticeable', 'compensated'] ----------- Opinion\n",
            "['outliers', 'fairly'] ----------- Opinion\n",
            "['overlay', 'tab'] ------------ Aspect\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.collocations import *\n",
        "from nltk.tokenize import word_tokenize\n",
        "asp_pmi=dict()\n",
        "for sentence in reviews:\n",
        "  text=word_tokenize(sentence.lower())\n",
        "  text=[token for token in text if token not in stop_words]\n",
        "  text=\" \".join(text)\n",
        "  text=re.sub(\"[^a-zA-z]+\",\" \",text)\n",
        "  bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
        "  finder = BigramCollocationFinder.from_words(word_tokenize(text))\n",
        "\n",
        "  for i in finder.score_ngrams(bigram_measures.pmi):\n",
        "    if i[0] not in asp_pmi.keys():\n",
        "      asp_pmi[i[0]]=+i[1]\n",
        "    else:\n",
        "      asp_pmi[i[0]]=i[1]\n",
        "ans=[]\n",
        "for i,j in asp_pmi.items():\n",
        "  ans.append([i,j])\n",
        "ans.sort(reverse=True,key=lambda f:f[1])\n",
        "\n",
        "#Printing the top 50 probable aspects\n",
        "for i in range(50):\n",
        "  token=nltk.word_tokenize(ans[i][0][0]+\" \"+ans[i][0][1])\n",
        "  if nltk.pos_tag(token)[0][1] in [\"NN\",\"NNS\"] and nltk.pos_tag(token)[0][1] ==\"NN\":\n",
        "    print(token,\"------------\",\"Aspect\")\n",
        "  elif nltk.pos_tag(token)[0][1]==\"RB\":\n",
        "    print(token,\"------------\",\"Intensifier\")\n",
        "  else:\n",
        "    print(token,\"-----------\",\"Opinion\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j56bLCgkMVJU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}